import logging
from typing import List, Optional
from pathlib import Path

from src.document_loader import DocumentLoader
from src.vector_store import VectorStore
from src.llm_handler import LLMHandler
from config.settings import DATA_PATH, SEARCH_K, SIMILARITY_THRESHOLD

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RAGPipeline:
    def __init__(self):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG –ø–∞–π–ø–ª–∞–π–Ω–∞
        """
        self.document_loader = DocumentLoader()
        self.vector_store = VectorStore()
        self.llm_handler = LLMHandler()

        logger.info("RAG Pipeline –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def load_documents(self, data_path: str = DATA_PATH) -> dict:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–∏ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        """
        try:
            logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑: {data_path}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏
            if not Path(data_path).exists():
                return {
                    "success": False,
                    "message": f"–ü–∞–ø–∫–∞ {data_path} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç",
                    "documents_loaded": 0
                }

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
            documents = self.document_loader.load_documents_from_directory(data_path)

            if not documents:
                return {
                    "success": False,
                    "message": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏",
                    "documents_loaded": 0
                }

            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            self.vector_store.add_documents(documents)

            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            collection_info = self.vector_store.get_collection_info()

            return {
                "success": True,
                "message": f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤/—á–∞–Ω–∫–æ–≤",
                "documents_loaded": len(documents),
                "total_in_collection": collection_info.get("document_count", 0)
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
            return {
                "success": False,
                "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ: {str(e)}",
                "documents_loaded": 0
            }

    def query(self, user_question: str, k: int = SEARCH_K) -> str:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ RAG –ø–∞–π–ø–ª–∞–π–Ω
        """
        try:
            if not user_question.strip():
                return "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å."

            logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å: {user_question}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –æ–±—â–∏–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ–º –∏–ª–∏ –≤–æ–ø—Ä–æ—Å–æ–º
            general_queries = self._is_general_query(user_question.lower())

            # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            relevant_docs = self.vector_store.search_similar_documents(
                query=user_question,
                k=k
            )

            # –û–¢–õ–ê–î–ö–ê - –ª–æ–≥–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(relevant_docs)}")
            for i, (doc, score) in enumerate(relevant_docs):
                logger.info(f"–î–æ–∫—É–º–µ–Ω—Ç {i + 1}: {doc.metadata.get('filename', 'unknown')} (score: {score:.3f})")

            # –ï—Å–ª–∏ —ç—Ç–æ –æ–±—â–∏–π –≤–æ–ø—Ä–æ—Å –∏ –Ω–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –æ—Ç–≤–µ—á–∞–µ–º –¥—Ä—É–∂–µ–ª—é–±–Ω–æ
            if general_queries and (
                    not relevant_docs or not any(score >= SIMILARITY_THRESHOLD for _, score in relevant_docs)):
                return self._handle_general_query(user_question)

            if not relevant_docs:
                return "–Ø —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Å—å –Ω–∞ –æ—Ç–≤–µ—Ç–∞—Ö –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –≤ –≤–∞—à–µ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º –≤–∞—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."

            # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –ø–æ—Ä–æ–≥—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            filtered_docs = [
                (doc, score) for doc, score in relevant_docs
                if score >= SIMILARITY_THRESHOLD
            ]

            # –û–¢–õ–ê–î–ö–ê - –ª–æ–≥–∏—Ä—É–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é
            logger.info(f"–ü–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏: {SIMILARITY_THRESHOLD}")
            logger.info(f"–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(filtered_docs)}")
            for i, (doc, score) in enumerate(filtered_docs):
                logger.info(f"–ü—Ä–æ—à–µ–ª —Ñ–∏–ª—å—Ç—Ä {i + 1}: {doc.metadata.get('filename', 'unknown')} (score: {score:.3f})")

            if not filtered_docs:
                # –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã –µ—Å—Ç—å, –Ω–æ –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã - –¥–∞–µ–º –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –æ—Ç–≤–µ—Ç
                logger.warning(
                    f"–í—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã! –õ—É—á—à–∏–π score: {relevant_docs[0][1] if relevant_docs else 'N/A'}")
                return "–Ø –Ω–µ –Ω–∞—à–µ–ª –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –≤–∞—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –¥–ª—è —ç—Ç–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –∑–∞–¥–∞—Ç—å –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É –≤–∞—à–∏—Ö —Ñ–∞–π–ª–æ–≤."

            # –û–¢–õ–ê–î–ö–ê - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–µ—Ä–µ–¥–∞–µ–º –≤ LLM
            logger.info(f"–ü–µ—Ä–µ–¥–∞–µ–º –≤ LLM {len(filtered_docs)} –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:")
            for i, (doc, score) in enumerate(filtered_docs, 1):
                filename = doc.metadata.get('filename', 'unknown')
                logger.info(f"  {i}. {filename} (score: {score:.3f})")

            # –í–ê–ñ–ù–û: –ø–µ—Ä–µ–¥–∞–µ–º –¢–û–õ–¨–ö–û –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã, –ù–ï –≤—Å–µ relevant_docs
            response = self.llm_handler.generate_response(
                query=user_question,
                relevant_docs=filtered_docs  # –¢–û–õ–¨–ö–û —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ!
            )

            return response

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."

    def query_stream(self, user_question: str, k: int = SEARCH_K):
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ RAG –ø–∞–π–ø–ª–∞–π–Ω –≤ –ø–æ—Ç–æ–∫–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
        """
        try:
            if not user_question.strip():
                yield "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å."
                return

            logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Ç–æ–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: {user_question}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –æ–±—â–∏–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ–º –∏–ª–∏ –≤–æ–ø—Ä–æ—Å–æ–º
            general_queries = self._is_general_query(user_question.lower())

            # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            relevant_docs = self.vector_store.search_similar_documents(
                query=user_question,
                k=k
            )

            # –ï—Å–ª–∏ —ç—Ç–æ –æ–±—â–∏–π –≤–æ–ø—Ä–æ—Å –∏ –Ω–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –æ—Ç–≤–µ—á–∞–µ–º –¥—Ä—É–∂–µ–ª—é–±–Ω–æ
            if general_queries and (
                    not relevant_docs or not any(score >= SIMILARITY_THRESHOLD for _, score in relevant_docs)):
                yield self._handle_general_query(user_question)
                return

            if not relevant_docs:
                yield "–Ø —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Å—å –Ω–∞ –æ—Ç–≤–µ—Ç–∞—Ö –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –≤ –≤–∞—à–µ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º –≤–∞—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."
                return

            # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –ø–æ—Ä–æ–≥—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            filtered_docs = [
                (doc, score) for doc, score in relevant_docs
                if score >= SIMILARITY_THRESHOLD
            ]

            if not filtered_docs:
                yield "–Ø –Ω–µ –Ω–∞—à–µ–ª –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –≤–∞—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –¥–ª—è —ç—Ç–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –∑–∞–¥–∞—Ç—å –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É –≤–∞—à–∏—Ö —Ñ–∞–π–ª–æ–≤."
                return

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é LLM –≤ –ø–æ—Ç–æ–∫–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
            for response_chunk in self.llm_handler.generate_response_stream(
                    query=user_question,
                    relevant_docs=filtered_docs
            ):
                yield response_chunk

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Ç–æ–∫–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            yield "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."

    def get_system_status(self) -> dict:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
        """
        try:
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            collection_info = self.vector_store.get_collection_info()

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ OpenAI
            openai_status = self.llm_handler.check_connection()

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –ø–∞–ø–∫–∏ —Å –¥–∞–Ω–Ω—ã–º–∏
            data_path_exists = Path(DATA_PATH).exists()

            return {
                "vector_store": {
                    "status": "‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç",
                    "collection_name": collection_info.get("name", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"),
                    "documents_count": collection_info.get("document_count", 0),
                    "embedding_model": collection_info.get("embedding_model", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                },
                "llm": {
                    "status": "‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç" if openai_status else "‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è",
                    "model": self.llm_handler.llm.model_name if hasattr(self.llm_handler.llm,
                                                                        'model_name') else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                },
                "data_path": {
                    "path": DATA_PATH,
                    "exists": "‚úÖ –°—É—â–µ—Å—Ç–≤—É–µ—Ç" if data_path_exists else "‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–∞",
                    "files_count": len(list(Path(DATA_PATH).rglob("*"))) if data_path_exists else 0
                }
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã: {e}")
            return {
                "error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞: {str(e)}"
            }

    def clear_vector_store(self) -> dict:
        """
        –û—á–∏—â–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
        """
        try:
            self.vector_store.clear_collection()
            return {
                "success": True,
                "message": "–í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –æ—á–∏—â–µ–Ω–æ"
            }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞: {e}")
            return {
                "success": False,
                "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ: {str(e)}"
            }

    def search_documents(self, query: str, k: int = SEARCH_K) -> List[dict]:
        """
        –ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –±–µ–∑ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
        """
        try:
            relevant_docs = self.vector_store.search_similar_documents(query, k)

            results = []
            for doc, score in relevant_docs:
                results.append({
                    "content": doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content,
                    "score": round(score, 3),
                    "filename": doc.metadata.get("filename", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"),
                    "directory": doc.metadata.get("directory", ""),
                    "chunk_index": doc.metadata.get("chunk_index", 0)
                })

            return results

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
            return []

    def _is_general_query(self, query: str) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–ø—Ä–æ—Å –æ–±—â–∏–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ–º –∏–ª–∏ –≤–æ–ø—Ä–æ—Å–æ–º
        """
        general_patterns = [
            '–ø—Ä–∏–≤–µ—Ç', 'hello', 'hi', '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π', '–¥–æ–±—Ä—ã–π –¥–µ–Ω—å', '–¥–æ–±—Ä—ã–π –≤–µ—á–µ—Ä',
            '–∫–∞–∫ –¥–µ–ª–∞', '—á—Ç–æ —É–º–µ–µ—à—å', '–ø–æ–º–æ–≥–∏', '–∫—Ç–æ —Ç—ã', '—á—Ç–æ —Ç—ã',
            '—Å–ø–∞—Å–∏–±–æ', 'thanks', 'thank you', '–ø–æ–∫–∞', 'bye', '–¥–æ —Å–≤–∏–¥–∞–Ω–∏—è'
        ]

        return any(pattern in query for pattern in general_patterns)

    def _handle_general_query(self, query: str) -> str:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–±—â–∏–µ –∑–∞–ø—Ä–æ—Å—ã –±–µ–∑ –ø–æ–∏—Å–∫–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
        """
        query_lower = query.lower()

        if any(word in query_lower for word in ['–ø—Ä–∏–≤–µ—Ç', 'hello', 'hi', '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π', '–¥–æ–±—Ä—ã–π']):
            return """–ü—Ä–∏–≤–µ—Ç! üëã 

–Ø –≤–∞—à –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏. –Ø –º–æ–≥—É –ø–æ–º–æ—á—å –≤–∞–º –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö –∏ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –∏—Ö —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É.

–ß—Ç–æ —è —É–º–µ—é:
‚Ä¢ –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É –≤–∞—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
‚Ä¢ –ò—Å–∫–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Ñ–∞–π–ª–∞—Ö
‚Ä¢ –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

–ó–∞–¥–∞–π—Ç–µ –º–Ω–µ –≤–æ–ø—Ä–æ—Å –æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º –≤–∞—à–∏—Ö —Ñ–∞–π–ª–æ–≤, –∏ —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –ø–æ–º–æ—á—å!"""

        elif any(word in query_lower for word in ['—á—Ç–æ —É–º–µ–µ—à—å', '—á—Ç–æ —Ç—ã', '–∫—Ç–æ —Ç—ã', '–ø–æ–º–æ–≥–∏']):
            return """–Ø –≤–∞—à –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏! ü§ñ

–ú–æ–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
‚Ä¢ üìö –ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –≤–∞—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (TXT, PDF, DOCX, CSV, MD)
‚Ä¢ üîç –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤—Å–µ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
‚Ä¢ üí° –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
‚Ä¢ üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ä–∞–∑–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

–ü—Ä–æ—Å—Ç–æ –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º –≤–∞—à–∏—Ö —Ñ–∞–π–ª–æ–≤, –Ω–∞–ø—Ä–∏–º–µ—Ä:
"–†–∞—Å—Å–∫–∞–∂–∏ –æ–± –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–µ –°—Ç—Ä—É–Ω–Ω–∏–∫–æ–≤–µ" –∏–ª–∏ "–ö–∞–∫–∏–µ –ø—Ä–æ–¥—É–∫—Ç—ã —É –Ω–∞—Å –µ—Å—Ç—å?" """

        elif any(word in query_lower for word in ['—Å–ø–∞—Å–∏–±–æ', 'thanks']):
            return "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞! –†–∞–¥ –±—ã–ª –ø–æ–º–æ—á—å. –ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –µ—â–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º, –æ–±—Ä–∞—â–∞–π—Ç–µ—Å—å! üòä"

        elif any(word in query_lower for word in ['–ø–æ–∫–∞', 'bye', '–¥–æ —Å–≤–∏–¥–∞–Ω–∏—è']):
            return "–î–æ —Å–≤–∏–¥–∞–Ω–∏—è! –£–¥–∞—á–∏ –≤ —Ä–∞–±–æ—Ç–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏! üëã"

        else:
            return "–Ø –≥–æ—Ç–æ–≤ –ø–æ–º–æ—á—å –≤–∞–º —Å –ø–æ–∏—Å–∫–æ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –≤–∞—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö. –ó–∞–¥–∞–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É —Ñ–∞–π–ª–æ–≤!"